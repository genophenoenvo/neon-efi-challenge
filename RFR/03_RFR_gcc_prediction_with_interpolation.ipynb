{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import TimeSeriesSplit\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#from sklearn.neighbors import KNeighborsRegressor\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.svm import SVR\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.metrics as metrics\n",
    "from datetime import date\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:(12496, 6)\n",
      "Sites:\n",
      "['HARV' 'BART' 'SCBI' 'STEI' 'UKFS' 'GRSM' 'DELA' 'CLBJ']\n"
     ]
    }
   ],
   "source": [
    "# Importing the dataset gcc_weather.csv\n",
    "url = \"https://raw.githubusercontent.com/genophenoenvo/neon-datasets/main/pheno_images/gcc_weather.csv\"\n",
    "dataset = pd.read_csv(url)\n",
    "\n",
    "# Creating columns year, month, day and setting the time as index to use 'shift' funtion() \n",
    "dataset['time'] = pd.to_datetime(dataset['time'])\n",
    "dataset['year'] = pd.DatetimeIndex(dataset['time']).year\n",
    "dataset['month'] = pd.DatetimeIndex(dataset['time']).month\n",
    "dataset['day'] = pd.DatetimeIndex(dataset['time']).day\n",
    "dataset['year_month']= dataset['year'].map(str) + \"-\" + dataset['month'].map(str)\n",
    "dataset = dataset.set_index(\"time\")\n",
    "\n",
    "# Selecting the required columns: siteID and gcc90 and date related columns\n",
    "gcc_data = dataset[[\"siteID\", \"gcc_90\", \"year\", \"month\", \"day\", \"year_month\"]]\n",
    "print(\"Shape:\" + str(gcc_data.shape))\n",
    "site_list = gcc_data[\"siteID\"].unique()\n",
    "print(\"Sites:\")\n",
    "print(site_list)\n",
    "\n",
    "#Create dataframes for each of the sites\n",
    "gcc_data_by_site = gcc_data.groupby(\"siteID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_pred_df = []\n",
    "input_features = []\n",
    "\n",
    "for i in range(0,8):\n",
    "    future_pred_df.append(gcc_data_by_site.get_group(site_list[i]))\n",
    "    future_pred_df[i].reset_index(inplace=True)\n",
    "\n",
    "for i in range(0,8):\n",
    "    date_range = pd.date_range(start=future_pred_df[i][\"time\"].max() + datetime.timedelta(1), \n",
    "                               end = date.today() + datetime.timedelta(1) , freq='D')\n",
    "    future_pred_df[i] = future_pred_df[i].append(pd.DataFrame({'time': date_range, \n",
    "                                                               'siteID': site_list[i]}))\n",
    "    future_pred_df[i].reset_index(inplace = True, drop = True)\n",
    "\n",
    "for k in range(0,8):\n",
    "    for i in range(1,6):     #Creating features columns for last 5 days\n",
    "        col_name = \"gcc_90_(t-\"+str(i)+\")\"\n",
    "        future_pred_df[k].loc[:,col_name] = future_pred_df[k].loc[:,\"gcc_90\"].shift(i)\n",
    "        future_pred_df[k].loc[:,col_name] = future_pred_df[k].loc[:,col_name].fillna(future_pred_df[k].loc[:,\"gcc_90\"].shift(365*i))\n",
    "        future_pred_df[k].loc[:,col_name] = future_pred_df[k].loc[:,col_name].fillna(future_pred_df[k].loc[:,\"gcc_90\"].shift(365*2*i))\n",
    "        future_pred_df[k].loc[:,col_name] = future_pred_df[k].loc[:,col_name].fillna(future_pred_df[k].loc[:,\"gcc_90\"].shift(365*3*i))\n",
    "        future_pred_df[k].loc[:,col_name] = future_pred_df[k].loc[:,col_name].ffill(axis = 0)\n",
    "        if(k == 0):\n",
    "            input_features.append(col_name)\n",
    "        \n",
    "    for i in range(1,6):     #Creating features columns for last 5 days from last year\n",
    "        col_name_last_year = \"last_year_gcc_90_(t-\"+str(i)+\")\"\n",
    "        future_pred_df[k].loc[:,col_name_last_year] = future_pred_df[k].loc[:,\"gcc_90\"].shift(i+365)\n",
    "        future_pred_df[k].loc[:,col_name_last_year] = future_pred_df[k].loc[:,col_name_last_year].fillna(future_pred_df[k].loc[:,\"gcc_90\"].shift(i+365*2))\n",
    "        future_pred_df[k].loc[:,col_name_last_year] = future_pred_df[k].loc[:,col_name_last_year].fillna(future_pred_df[k].loc[:,\"gcc_90\"].shift(i+365*3))\n",
    "        future_pred_df[k].loc[:,col_name_last_year] = future_pred_df[k].loc[:,col_name_last_year].ffill(axis=0)\n",
    "        if(k == 0):\n",
    "            input_features.append(col_name_last_year)\n",
    "            \n",
    "    for i in range(0,15):     #Creating features columns for t to (t+14) days from last year\n",
    "        col_name_last_year_ahead = \"last_year_gcc_90_(t+\"+str(i)+\")\"\n",
    "        future_pred_df[k].loc[:,col_name_last_year_ahead] = future_pred_df[k].loc[:,\"gcc_90\"].shift(365-i)\n",
    "        future_pred_df[k].loc[:,col_name_last_year_ahead] = future_pred_df[k].loc[:,col_name_last_year_ahead].fillna(future_pred_df[k].loc[:,\"gcc_90\"].shift(365*2-i))\n",
    "        future_pred_df[k].loc[:,col_name_last_year_ahead] = future_pred_df[k].loc[:,col_name_last_year_ahead].fillna(future_pred_df[k].loc[:,\"gcc_90\"].shift(365*3-i))\n",
    "        future_pred_df[k].loc[:,col_name_last_year_ahead] = future_pred_df[k].loc[:,col_name_last_year_ahead].ffill(axis=0)\n",
    "        if(k == 0):\n",
    "            input_features.append(col_name_last_year_ahead)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palde\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:691: PerformanceWarning: Non-vectorized DateOffset being applied to Series or DatetimeIndex\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "date_index = pd.Timestamp(date.today())\n",
    "future_pred_date_range = pd.date_range(date_index, periods=36, freq='D')\n",
    "future_pred_35 = pd.DataFrame(columns = ['time', 'siteID', 'gcc_90'])\n",
    "\n",
    "for k in range(0,8):\n",
    "    input_record = future_pred_df[k][future_pred_df[k][\"time\"] == date_index]\n",
    "    if(input_record[input_features].isnull().values.any()):\n",
    "        print(\"Missing values present in the input features for\" + site_list[k])\n",
    "    \n",
    "    file_name = \"model_\"+site_list[k]+\".pkl\"\n",
    "    model = pickle.load(open(file_name,'rb'))\n",
    "    future_pred = model.predict(input_record[input_features])\n",
    "    \n",
    "    future_pred_35 = future_pred_35.append(pd.DataFrame({'time': future_pred_date_range, \n",
    "                                                  'siteID': site_list[k],\n",
    "                                                  'gcc_90': pd.Series(future_pred[0])\n",
    "                                                        }))\n",
    "\n",
    "last_year_df = dataset[dataset.columns.intersection(['siteID', 'gcc_sd'])].loc['2020',:].reset_index()\n",
    "last_year_df['time'] = last_year_df['time'].mask(last_year_df['time'].dt.year == 2020, \n",
    "                             last_year_df['time'] + pd.offsets.DateOffset(year=2021))\n",
    "last_year_df = last_year_df.ffill(axis=0)\n",
    "\n",
    "output_file_name= \"prediction_interpolation_\" + str(date.today().strftime(\"%m-%d-%y\"))+ \".csv\"\n",
    "final_output = pd.merge(left=future_pred_35, right=last_year_df, how='left', left_on=['time','siteID'], right_on=['time','siteID'])\n",
    "final_output.to_csv(output_file_name, index=False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
